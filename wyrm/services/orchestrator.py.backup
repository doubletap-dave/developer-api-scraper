"""Orchestrator service for Wyrm application.

This service coordinates the entire scraping workflow by delegating to
specialized services for configuration, navigation, parsing, storage, and progress.
"""


import asyncio
import sys
from pathlib import Path
from typing import Dict, List, Optional

import structlog

from wyrm.models.config import AppConfig
from wyrm.models.scrape import SidebarStructure, SidebarItem
from wyrm.services.configuration_service import ConfigurationService
from wyrm.services.navigation import NavigationService
from wyrm.services.parallel_orchestrator import ParallelOrchestrator
from wyrm.services.parsing import ParsingService
from wyrm.services.progress_service import ProgressService
from wyrm.services.storage import StorageService


class Orchestrator:
    """Main orchestrator service for the Wyrm scraping application.

    This service coordinates the entire workflow by delegating to specialized
    services for different aspects of the scraping process. It handles the
    high-level flow from configuration loading through final content extraction.

    The orchestrator ensures proper error handling, resource cleanup, and
    progress reporting throughout the scraping workflow.

    Attributes:
        config_service: Service for configuration loading and validation.
        navigation_service: Service for browser automation and navigation.
        parsing_service: Service for HTML parsing and structure extraction.
        storage_service: Service for file operations and content storage.
        progress_service: Service for progress tracking and reporting.
    """

    def __init__(self) -> None:
        """Initialize the Orchestrator service.

        Creates instances of all required services for the scraping workflow.
        Services are initialized with default configurations and can be
        customized through the configuration loading process.

        Args:
            None

        Returns:
            None
        """
        self.logger = structlog.get_logger(__name__)
        self.config_service = ConfigurationService()
        self.navigation_service = NavigationService()
        self.parsing_service = ParsingService()
        self.storage_service = StorageService()
        self.progress_service = ProgressService()
        self._config = None  # Store config for cleanup
        self._full_expansion_done = False  # Prevents duplicate full-site expansions

    async def run_scraping_workflow(
        self,
        config_path: str,
        headless: Optional[bool] = None,
        log_level: Optional[str] = None,
        save_structure: bool = False,
        save_html: bool = False,
        debug: bool = False,
        max_expand_attempts: Optional[int] = None,
        force: bool = False,
        test_item_id: Optional[str] = None,
        max_items: Optional[int] = None,
        resume_info: bool = False,
        structure_filename: Optional[str] = None,
        html_filename: Optional[str] = None,
        force_full_expansion: bool = False,
    ) -> None:
        """Run the complete scraping workflow.

        Coordinates the entire scraping process from configuration loading
        through final content extraction. Handles CLI overrides, debug modes,
        and provides comprehensive error handling with proper cleanup.

        Args:
            config_path: Path to YAML configuration file.
            headless: Override headless browser mode. If None, uses config value.
            log_level: Override logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL).
            save_structure: Whether to save parsed structure to debug directory.
            save_html: Whether to save raw HTML to debug directory.
            debug: Enable comprehensive debug mode with additional logging and saves.
            max_expand_attempts: Override maximum menu expansion attempts.
            force: Overwrite existing output files instead of skipping them.
            test_item_id: DEPRECATED. Process only the specified item ID.
            max_items: Maximum number of items to process.
            resume_info: Display resume information and exit without processing.
            structure_filename: Custom filename for saved structure (optional).
            html_filename: Custom filename for saved HTML (optional).

        Returns:
            None

        Raises:
            Exception: Re-raises any unexpected errors after logging.
            KeyboardInterrupt: Re-raises user interruption after cleanup.
        """
        try:
            # Load configuration and setup
            config = self.config_service.load_config(config_path)

            # Merge CLI overrides
            cli_args = {
                "headless": headless,
                "log_level": log_level,
                "max_expand_attempts": max_expand_attempts,
                "force_full_expansion": force_full_expansion,
            }
            config = self.config_service.merge_cli_overrides(config, cli_args)

            # Store config for cleanup
            self._config = config

            if debug:
                save_structure = True
                save_html = True
                self.logger.info(
                    "Debug mode enabled - forcing structure and HTML saves"
                )

            # Get configuration values
            config_values = self.config_service.extract_configuration_values(config)

            # Initialize endpoint-aware services
            self._initialize_endpoint_aware_services(config)

            # Setup directories
            self.config_service.setup_directories(config_values)

            # Handle sidebar structure loading/parsing
            sidebar_structure, from_cache = await self._handle_sidebar_structure(
                config, config_values, save_structure, save_html,
                structure_filename, html_filename, resume_info, force
            )

            # Process items from structure
            await self._process_items_from_structure(
                sidebar_structure, config_values, force,
                test_item_id, max_items, resume_info, from_cache
            )

        except KeyboardInterrupt:
            self.logger.warning("User interrupted execution")
            raise
        except Exception as e:
            self.logger.exception("An unexpected error occurred", error=str(e))
            raise
        finally:
            await self._cleanup()

    async def _handle_sidebar_structure(
        self,
        config: AppConfig,
        config_values: Dict,
        save_structure: bool,
        save_html: bool,
        structure_filename: Optional[str],
        html_filename: Optional[str],
        resume_info: bool,
        force: bool,
    ) -> tuple[SidebarStructure, bool]:
        """Handle sidebar structure loading or parsing.

        Attempts to load existing structure from file first. If not found or
        force flag is set, performs live parsing by navigating to the target
        site and extracting the sidebar structure.

        Args:
            config: Application configuration with all settings.
            config_values: Extracted configuration values dictionary.
            save_structure: Whether to save parsed structure to debug directory.
            save_html: Whether to save raw HTML to debug directory.
            structure_filename: Custom filename for structure save (optional).
            html_filename: Custom filename for HTML save (optional).
            resume_info: Whether this is for resume info display only.
            force: Whether to force re-parsing even if structure exists.

        Returns:
            SidebarStructure: Parsed or loaded sidebar structure.

        Raises:
            Exception: If structure loading/parsing fails.
        """
        # Use debug directory for structure file only in debug mode
        if save_structure:
            structure_filepath = self.parsing_service.get_structure_filepath(
                config_values)
        else:
            # In normal mode, use logs directory for structure file
            structure_filepath = Path("logs") / "sidebar_structure.json"

        # Try to load existing structure first
        sidebar_structure, from_cache = self.parsing_service.load_existing_structure(
            structure_filepath
        )

        # Check if structure is valid and has usable items
        structure_is_valid = False
        if sidebar_structure and not force:
            try:
                # Convert to SidebarStructure model to check validity
                temp_structure = SidebarStructure(
                    structured_data=sidebar_structure.get('structured_data', []),
                    items=[SidebarItem(**item)
                           for item in sidebar_structure.get('items', [])]
                )
                valid_items = temp_structure.valid_items
                total_items = len(sidebar_structure.get('items', []))

                # Require a reasonable number of valid items for a complete structure
                # If we have many total items but few valid ones, it's likely an incomplete parse
                min_valid_items = 10  # Expect at least 10 valid items for a complete API docs structure
                valid_item_ratio = len(valid_items) / max(total_items, 1)

                if len(valid_items) >= min_valid_items and valid_item_ratio > 0.1:
                    structure_is_valid = True
                    self.logger.info(
                        "Using existing structure with sufficient valid items",
                        valid_items_count=len(valid_items),
                        total_items=total_items,
                        valid_ratio=f"{valid_item_ratio:.2%}"
                    )
                else:
                    self.logger.info(
                        "Existing structure insufficient, will re-parse",
                        total_items=total_items,
                        valid_items_count=len(valid_items),
                        valid_ratio=f"{valid_item_ratio:.2%}",
                        reason="too few valid items" if len(
                            valid_items) < min_valid_items else "low valid ratio"
                    )
            except Exception as e:
                self.logger.warning(
                    "Failed to validate existing structure, will re-parse",
                    error=str(e)
                )

        if not structure_is_valid:
            # Need to parse live
            sidebar_structure = await self._perform_live_parsing(
                config, config_values, save_structure, save_html,
                structure_filename, html_filename, structure_filepath
            )
            from_cache = False

        # Handle resume check
        await self._handle_resume_check(
            sidebar_structure, config_values, resume_info, force
        )

        return sidebar_structure, from_cache

    async def _perform_live_parsing(
        self,
        config: AppConfig,
        config_values: Dict,
        save_structure: bool,
        save_html: bool,
        structure_filename: Optional[str],
        html_filename: Optional[str],
        structure_filepath,
    ) -> SidebarStructure:
        """Perform live parsing of sidebar structure.

        Initializes browser driver, navigates to target URL, extracts sidebar HTML,
        and parses it into a structured format. Optionally saves debug files.

        Args:
            config: Application configuration with navigation settings.
            config_values: Extracted configuration values dictionary.
            save_structure: Whether to save parsed structure to debug directory.
            save_html: Whether to save raw HTML to debug directory.
            structure_filename: Custom filename for structure save (optional).
            html_filename: Custom filename for HTML save (optional).
            structure_filepath: Path where structure should be saved.

        Returns:
            SidebarStructure: Newly parsed sidebar structure.

        Raises:
            Exception: If navigation or parsing fails.
        """
        # Initialize driver and navigate
        await self.navigation_service.initialize_driver(config)
        self.logger.info("Navigating to target URL and waiting for sidebar...")
        sidebar_html = await self.navigation_service.navigate_and_wait(
            config, config_values
        )

        self.logger.info("Performing menu expansion to reveal all items...")
        await self.navigation_service.expand_all_menus_comprehensive()
        self._full_expansion_done = True

        self.logger.info("Extracting fully expanded sidebar structure...")
        # Get the updated sidebar HTML after expansion
        expanded_sidebar_html = await self.navigation_service.get_sidebar_html()

        # Log comparison for debugging
        initial_html_length = len(sidebar_html)
        expanded_html_length = len(expanded_sidebar_html)
        self.logger.info(
            "Menu expansion completed",
            initial_html_length=initial_html_length,
            expanded_html_length=expanded_html_length
        )

        # Use the expanded HTML for parsing
        sidebar_html = expanded_sidebar_html

        # Save debug files if requested
        if save_html:
            await self.parsing_service.save_debug_html(
                sidebar_html, config_values, html_filename
            )

        # Parse and save structure
        sidebar_structure = await self.parsing_service.parse_sidebar_structure(
            sidebar_html
        )

        # Save structure to the determined filepath (debug or normal location)
        self.storage_service.save_structure_to_output(
            sidebar_structure, structure_filepath
        )
        return sidebar_structure

    async def _handle_resume_check(
        self,
        sidebar_structure: SidebarStructure,
        config_values: Dict,
        resume_info: bool,
        force: bool,
    ) -> None:
        """Handle resume information display and validation.

        Sets up progress tracking with total item count and optionally displays
        resume information showing existing vs missing files before exiting.

        Args:
            sidebar_structure: Parsed sidebar structure with all items.
            config_values: Configuration values including output directory.
            resume_info: Whether to display resume information and exit.
            force: Whether force mode is enabled (affects resume display).

        Returns:
            None

        Raises:
            SystemExit: If resume_info is True, exits after displaying information.
        """
        valid_items = self.parsing_service._get_valid_items(sidebar_structure)
        self.progress_service.set_total_items(len(valid_items))

        if resume_info:
            existing_items, items_needing_processing = (
                self.storage_service.check_existing_files(
                    valid_items, config_values["base_output_dir"]
                )
            )
            self.storage_service.display_resume_info(
                valid_items,
                existing_items,
                items_needing_processing,
                config_values["base_output_dir"]
            )
            sys.exit(0)

    async def _process_items_from_structure(
        self,
        sidebar_structure: SidebarStructure,
        config_values: Dict,
        force: bool,
        test_item_id: Optional[str],
        max_items: Optional[int],
        resume_info: bool,
        from_cache: bool,
    ) -> None:
        """Process items from the sidebar structure.

        Filters items based on provided criteria and processes them for content
        extraction. Handles test mode, item limits, and force overrides.

        Args:
            sidebar_structure: Parsed sidebar structure containing all items.
            config_values: Configuration values for processing.
            force: Whether to overwrite existing files.
            test_item_id: DEPRECATED. Specific item ID to process.
            max_items: Maximum number of items to process.
            resume_info: Whether this is resume info mode (affects processing).

        Returns:
            None

        Raises:
            Exception: If item processing fails.
        """
        valid_items = self.parsing_service._get_valid_items(sidebar_structure)

        # Filter items for processing
        items_to_process = self.parsing_service.filter_items_for_processing(
            valid_items, max_items, test_item_id
        )

        # Log whether structure came from cache or was parsed live
        if from_cache:
            self.logger.info(
                "Processing items from cached structure",
                count=len(items_to_process),
                source="cache"
            )
        else:
            self.logger.info(
                "Processing items from live-parsed structure",
                count=len(items_to_process),
                source="live_parsing"
            )

        self.logger.info("Processing items", count=len(items_to_process))

        # CRITICAL: Ensure NavigationService is initialized before processing items
        # This must happen regardless of whether we did live parsing or loaded from cache
        if not self.navigation_service.get_driver():
            self.logger.info("Initializing NavigationService for item processing")
            await self.navigation_service.initialize_driver(self._config)
            self.logger.info("NavigationService initialized successfully")

            # When using cached data, we need to navigate to the site and expand menus
            # since the browser session is fresh and menus are collapsed
            self.logger.info(
                "Navigating to site and expanding menus for cached data processing...")
            await self.navigation_service.navigate_and_wait(self._config, config_values)

            # Conditional menu expansion logic
            should_expand = False
            expansion_reason = ""

            if not from_cache:
                # Always expand when structure was just parsed (not from cache)
                should_expand = True
                expansion_reason = "structure was just parsed (not from cache)"
            elif from_cache and not self._full_expansion_done:
                # Check if force_full_expansion flag, force override, or validate_cache config is set
                if config_values.get('force_full_expansion', False):
                    should_expand = True
                    expansion_reason = "force_full_expansion flag enabled"
                elif force or config_values.get('validate_cache', False):
                    should_expand = True
                    expansion_reason = "force override or validate_cache enabled"
                else:
                    # Skip expansion for cached data when full expansion not done
                    self.logger.info(
                        "Skipping full menu expansion for cached structure - relying on per-item expansion",
                        reason="using cached structure and no force/validate_cache override"
                    )
            elif self._full_expansion_done:
                # Already expanded in this session
                self.logger.info(
                    "Menu expansion already completed in this session, skipping")

            if should_expand:
                self.logger.info(f"Expanding all menus - {expansion_reason}")
                await self.navigation_service.expand_all_menus_comprehensive()
                self._full_expansion_done = True
                self.logger.info(
                    "Menu expansion completed - items should now be accessible")

        # Choose processing mode: parallel or sequential
        await self._process_items_hybrid_mode(items_to_process, config_values)

    async def _process_items_hybrid_mode(
        self,
        items_to_process: List[Dict],
        config_values: Dict,
    ) -> None:
        """Choose between parallel and sequential processing modes.

        This method implements the hybrid approach:
        1. Check if parallel processing is enabled and feasible
        2. Estimate performance benefits
        3. Choose the optimal processing mode
        4. Provide graceful fallback if parallel processing fails

        Args:
            items_to_process: List of sidebar items to process
            config_values: Configuration values including concurrency settings

        Returns:
            None
        """
        num_items = len(items_to_process)

        # Check if parallel processing is enabled
        if not config_values.get('concurrency_enabled', True):
            self.logger.info(
                "Parallel processing disabled in configuration, using sequential mode"
            )
            await self._process_items_with_progress(items_to_process, config_values)
            return

        # For small numbers of items, sequential might be faster due to overhead
        min_items_for_parallel = 5
        if num_items < min_items_for_parallel:
            self.logger.info(
                "Item count below parallel threshold, using sequential mode",
                item_count=num_items,
                threshold=min_items_for_parallel
            )
            await self._process_items_with_progress(items_to_process, config_values)
            return

        # Create parallel orchestrator and estimate performance
        parallel_orchestrator = ParallelOrchestrator(self.progress_service)
        time_estimates = await parallel_orchestrator.estimate_processing_time(
            num_items, config_values
        )

        # Log performance estimates
        self.logger.info(
            "Processing mode analysis",
            items=num_items,
            sequential_estimate_min=int(time_estimates['sequential_estimate'] / 60),
            parallel_estimate_min=int(time_estimates['parallel_estimate'] / 60),
            speedup_factor=f"{time_estimates['parallel_speedup']:.1f}x"
        )

        # Use parallel if it offers significant speedup (>1.3x)
        min_speedup = 1.3
        if time_estimates['parallel_speedup'] >= min_speedup:
            try:
                self.logger.info(
                    "Using parallel processing mode",
                    max_workers=config_values.get('max_concurrent_tasks', 3),
                    expected_speedup=f"{time_estimates['parallel_speedup']:.1f}x"
                )

                # Convert dict items to SidebarItem objects for parallel processing
                sidebar_items = []
                for item in items_to_process:
                    if hasattr(item, 'id'):  # Already a SidebarItem
                        sidebar_items.append(item)
                    else:  # Dict item, convert to SidebarItem
                        try:
                            sidebar_item = SidebarItem(**item)
                            sidebar_items.append(sidebar_item)
                        except Exception as e:
                            self.logger.warning(
                                "Failed to convert item to SidebarItem, skipping",
                                item=item,
                                error=str(e)
                            )
                            continue

                # Process with parallel orchestrator
                results = await parallel_orchestrator.process_items_parallel(
                    sidebar_items, self._config, config_values
                )

                self.logger.info(
                    "Parallel processing completed",
                    processed=results['processed'],
                    failed=results['failed'],
                    skipped=results['skipped']
                )
                return

            except Exception as e:
                self.logger.error(
                    "Parallel processing failed, falling back to sequential",
                    error=str(e)
                )
                # Fall through to sequential processing
        else:
            self.logger.info(
                "Sequential processing preferred based on performance analysis",
                speedup_factor=f"{time_estimates['parallel_speedup']:.1f}x",
                min_required=f"{min_speedup}x"
            )

        # Use sequential processing (fallback or by choice)
        await self._process_items_with_progress(items_to_process, config_values)

    async def _process_items_with_progress(
        self,
        items_to_process: List[Dict],
        config_values: Dict,
    ) -> None:
        """Process items with progress tracking and reporting.

        Iterates through items and processes each one individually while
        maintaining progress reporting and error handling for individual failures.

        Args:
            items_to_process: List of sidebar items to process.
            config_values: Configuration values for processing.

        Returns:
            None

        Raises:
            Exception: If critical processing failures occur.
        """
        progress = self.progress_service.create_progress_display()

        with self.progress_service._suppress_console_logging():
            with progress:
                task_id = progress.add_task(
                    "Processing items...", total=len(items_to_process)
                )

                for item in items_to_process:
                    try:
                        await self._process_single_item(
                            item, config_values, progress, task_id
                        )
                    except Exception as e:
                        # Log to file only during progress display
                        self.logger.error(
                            "Failed to process item",
                            item_id=getattr(item, 'id', 'unknown'),
                            item_text=getattr(item, 'text', 'unknown'),
                            error=str(e)
                        )
                        continue

    async def _process_single_item(
        self,
        item,
        config_values: Dict,
        progress,
        task_id: int,
    ) -> None:
        """Process a single sidebar item.

        Handles the complete processing workflow for an individual item,
        including navigation, content extraction, and file saving.

        Args:
            item: Sidebar item to process (dict or SidebarItem).
            config_values: Configuration values for processing.
            progress: Progress display instance for updates.
            task_id: Task ID for progress tracking.

        Returns:
            None

        Raises:
            Exception: If item processing fails after retries.
        """
        # Handle both dict and SidebarItem objects
        item_text = item.text if hasattr(item, 'text') else item.get('text', 'Unknown')
        item_id = getattr(item, 'id', None) or item.get(
            'id', 'unknown') if isinstance(item, dict) else 'unknown'

        progress.update(task_id, description=f"Processing: {item_text}")

        # Check if file already exists (unless force mode)
        if not config_values.get('force', False):
            output_path = self.storage_service.get_output_path(
                item, config_values["base_output_dir"]
            )
            if output_path.exists():
                self.logger.info(
                    "Skipping existing file", path=str(output_path)
                )
                progress.advance(task_id)
                return

        # Process with retry logic for WebDriver failures
        max_retries = 2
        for attempt in range(max_retries + 1):
            try:
                # Verify NavigationService is ready before proceeding
                if not self.navigation_service.get_driver():
                    if attempt == 0:
                        # First attempt - reinitialize driver
                        self.logger.warning(
                            "WebDriver not available, reinitializing...",
                            item_text=item_text
                        )
                        await self.navigation_service.initialize_driver(self._config)
                    else:
                        raise RuntimeError(
                            f"NavigationService failed to initialize after retries for item: {item_text}"
                        )

                # Navigate to item and extract/save content
                await self.navigation_service.navigate_to_item(item)

                # Get the driver from navigation service to pass to storage service
                driver = self.navigation_service.get_driver()

                # Extract and save content in one step
                await self.storage_service.save_content_for_item(
                    item, driver, config_values
                )

                progress.advance(task_id)
                self.logger.info("Completed processing", item_text=item_text)
                return  # Success - exit retry loop

            except Exception as e:
                error_msg = str(e)
                is_webdriver_error = any(indicator in error_msg.lower() for indicator in [
                    'connection refused', 'session', 'webdriver', 'timeout',
                    'element not found', 'no such element', 'stale element'
                ])

                if is_webdriver_error and attempt < max_retries:
                    self.logger.warning(
                        f"WebDriver error on attempt {attempt + 1}, retrying...",
                        item_text=item_text,
                        item_id=item_id,
                        error=error_msg[:200],  # Truncate long error messages
                        attempt=attempt + 1,
                        max_retries=max_retries
                    )

                    # Clean up and reinitialize WebDriver
                    try:
                        await self.navigation_service.cleanup(self._config)
                    except Exception:
                        pass  # Ignore cleanup errors

                    # Wait before retry
                    await asyncio.sleep(2.0 * (attempt + 1))  # Progressive backoff

                    try:
                        await self.navigation_service.initialize_driver(self._config)
                    except Exception as init_error:
                        self.logger.error(
                            "Failed to reinitialize WebDriver",
                            item_text=item_text,
                            init_error=str(init_error)
                        )
                        if attempt == max_retries:
                            raise
                        continue
                else:
                    # Non-WebDriver error or max retries reached
                    self.logger.error(
                        "Failed to process item after retries",
                        item_text=item_text,
                        item_id=item_id,
                        error=error_msg[:200],
                        attempt=attempt + 1,
                        is_webdriver_error=is_webdriver_error
                    )
                    raise

    async def _cleanup(self) -> None:
        """Perform cleanup operations.

        Ensures proper cleanup of resources like browser drivers and
        temporary files. Called in the finally block of the main workflow.

        Args:
            None

        Returns:
            None

        Raises:
            Exception: Logs but doesn't re-raise cleanup errors.
        """
        try:
            if self._config:
                await self.navigation_service.cleanup(self._config)
            else:
                self.logger.warning("No config available for cleanup")
            self.logger.info("Cleanup completed successfully")
        except Exception as e:
            self.logger.error("Error during cleanup", error=str(e))

    def _initialize_endpoint_aware_services(self, config: AppConfig) -> None:
        """Initialize services that need to be aware of the endpoint version.

        Args:
            config: Application configuration containing target URL
        """
        # Create endpoint-aware selectors service
        from .selectors_service import SelectorsService
        selectors_service = SelectorsService.create_for_url(config.target_url)

        # Initialize parsing service with endpoint-aware selectors
        from .parsing import ParsingService
        self.parsing_service = ParsingService(selectors_service)

        # Update navigation service with endpoint-aware selectors
        self.navigation_service.selectors = selectors_service

        self.logger.info(
            "Initialized endpoint-aware services",
            endpoint_version=selectors_service.endpoint_version,
            structure_type=getattr(selectors_service, 'CONTENT_STRUCTURE_TYPE', 'hierarchical'),
            target_url=config.target_url
        )
